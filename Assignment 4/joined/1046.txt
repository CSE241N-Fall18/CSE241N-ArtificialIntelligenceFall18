Search term brings back mainly results of black women, which some say is evidence of bias. But algorithms may just be reflecting the wider social landscape 
 Recently, an MBA student named Rosalia discovered something alarming: Googling â€œunprofessional hairstyles for workâ€ yielded image results mainly of black women with natural hair, while searching for the â€œprofessionalâ€ ones offered pictures of coiffed, white women. Often the hair styles themselves were not vastly different -- only the hair type and the wearerâ€™s skin. Rosaliaâ€™s tweet has since been retweeted thousands of times - more than 6,200 in the first 24 hours, she says - as her discovery sparked discussion on implicit racial biases against black people in the workplace. Can an algorithm itself be racist? Or is it only reflecting the wider social landscape? I saw a tweet saying "Google unprofessional hairstyles for work". I did. Then I checked the 'professional' ones ğŸ™ƒğŸ™ƒğŸ™ƒ pic.twitter.com/5KLg7FZ6Hq It seems hard to remember a time when you couldnâ€™t just â€œGoogle Imagesâ€ a word or phrase and see a picture of it instantaneously. According to Google executive chairman Eric Schmidt, the feature was introduced in the year 2000. It was in response to sudden, overwhelming demand: Jennifer Lopez famously wore a plummeting, green Versace gown to that yearâ€™s Grammy awards and suddenly everyone wanted to see it. No one was Googling it just to read about it, that was for sure.  Now, Google Images is a practically thoughtless part of the way we use the web, instantaneously offering us a vast gallery of relevant images in response to a single word, phrase or query. It also makes further suggestions. If you search pie, youâ€™ll see classic confections both whole and sliced, as well as some available subsets. Apple pie, meat pie? Did you mean the mathematical number, maybe? Google Images thinks of everything! Weâ€™ve always conceived of search engines as arcane but neutral creatures, obedient only to our will and to the precious logic of information. Older engines from the advent of the internet reflected this: Remember â€œAsk Jeeves,â€ the genteel butler? Dogpile, which would â€œfetchâ€ things for you? Despite this fantasy, the things engines and their algorithms are able to know and to find are influenced by the content we give them to work with, which means they may reflect our own biases. On a basic level, Google Images primarily figures out who or what is shown in a picture by judging the text and captions that surround it. Itâ€™s possible though that some rudimentary image analysis - the kind that can tell a face from a landscape - is also involved. In the case of the great hair debate, Google Images seems to have taken many of the pictures of black women wearing the â€œunprofessionalâ€ hairstyles were from blogs, articles and Pinterest boards. Many of these are by people of colour explicitly discussing and protesting against racist attitudes to hair. One image led me to a post criticising Hampton Universityâ€™s ban on dreadlocks and cornrows; another was linked with a post celebrating natural hair and the â€œridiculousâ€ pressure to straighten it for the office; hereâ€™s a rejection of the idea that big, natural curls are â€œdistractingâ€ in a newsroom. Ultimately, the algorithm is mirroring conversations about â€œunprofessional hairâ€ biases, not making a ruling. In fact, just a day after Rosaliaâ€™s tweet went viral, memes about the discrepancy, screencaps of the tweet itself, and other recent related images topped the results of the Google Images search for â€œunprofessional hairstyles for workâ€. But it still raises questions about the role of algorithms in how we use the web, and pokes a few holes in the utopian fantasy of what the internet is for. For example, search for the word â€œmanâ€, and you get images almost entirely of white men, albeit of varying ages. A search for the word â€œwomanâ€ also reveals an overwhelming majority of young, white women. Considering that the majority of the global population is non-white, we do immediately see how white, western-centric biases - from race and gender beliefs to cultural standards of beauty and value - dominate the very way the web works and what stories it tells about humanity. The algorithm doesnâ€™t mean to be imperialist, of course. It does what itâ€™s designed to do: reflect the content that it has available. But the dream of the web as a â€œgreat equaliserâ€ remains only that, and the fantasy of a truly non-judgmental, universal digital servant who shows us the true size and scope of the world is still unfulfilled. Is this something Google can â€œsolve forâ€, perhaps by tagging and prioritising images differently? And if so, ought it to? These questions get at the very identity of â€œsearchâ€ as a digital concept: is its purpose to reflect and reinforce what its users feel, do and believe? Or is it to show us a fuller picture of the world and all things contained in it as they really are? Google Images was conceived in response to what people most wanted to see. Maybe it hasnâ€™t decided yet what we most need to see. 